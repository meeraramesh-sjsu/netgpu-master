/* 
	MODULE: Multi Level Flow 
	TYPE: Operation

	PrePreprocessor orders (ppp.sh): 

	###PATTERNS $THROUGHPUTS$MULTI_THRESHOLDS$MODIFY_THRESHOLD( 
*/



#ifdef __CUDACC__

//#warning Loaded Multi Throughput Thresholds operation module

#define $THROUGHPUTS$MULTI_THRESHOLDS$MODIFY_THRESHOLD(COND, NEW_LIMIT)\
	COMPOUND_NAME(ANALYSIS_NAME,multiFlowImplementation)(GPU_results, state, (COND),NEW_LIMIT)

	template<typename R>
	__device__ void COMPOUND_NAME(ANALYSIS_NAME,multiFlowImplementation)(R* GPU_results, analysisState_t state, bool cond, int newLimit){
		#include "../../CheckMultiKernelOperationFlag.def"		
	
//		IF_OPERATION_HAS_PERMISSION(){
		//Only makes sense when window limit has been reached
		if(state.windowState.hasReachedWindowLimit){
		 
			__shared__ R nullElement;
			__shared__ int blockElements;
			state.blockIterator = blockIdx.x;
			
			if(threadIdx.x == 0)
				cudaSharedMemset(&nullElement,0);
			
			while( state.blockIterator < state.windowState.totalNumberOfBlocks ){
				
				if(threadIdx.x == 0)
					blockElements = state.GPU_auxBlocks[state.blockIterator];
				SYNCTHREADS();
				
				if(threadIdx.x < blockElements){
					if( (cond) && (GPU_results[state.blockIterator*blockDim.x+threadIdx.x].rate < newLimit) )
						GPU_results[state.blockIterator*blockDim.x+threadIdx.x] = nullElement;
				}
				
				state.blockIterator += gridDim.x;
				SYNCTHREADS();
			}
		}
	}

//TODO: use CONDITIONS AND FILTERING when implemented

#endif // __CUDACC__
