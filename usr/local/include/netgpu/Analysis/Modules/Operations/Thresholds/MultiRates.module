/* 
	MODULE: Multi Level Rate 
	TYPE: Operation

	PrePreprocessor orders (ppp.sh): 

	###PATTERNS $RATES$MULTI_THRESHOLDS$MODIFY_THRESHOLD( 
*/


#ifdef __CUDACC__

//#warning Loaded Multi Flow Threshold operation


#define $RATES$MULTI_THRESHOLDS$MODIFY_THRESHOLD(COND, NEW_LIMIT)\
	COMPOUND_NAME(ANALYSIS_NAME,multiRateImplementation)(GPU_results, state, (COND),NEW_LIMIT)

	template<typename R>
	__device__ void COMPOUND_NAME(ANALYSIS_NAME,multiRateImplementation)(R* GPU_results, analysisState_t state, bool cond, int newLimit){
		#include "../../CheckMultiKernelOperationFlag.def"		
//		IF_OPERATION_HAS_PERMISSION(){ 
		if(state.windowState.hasReachedWindowLimit){
			__shared__ R nullElement;
			__shared__ int blockElements;
			state.blockIterator = blockIdx.x;
			
			if(threadIdx.x == 0)
				cudaSharedMemset(&nullElement,0);
			
			while( state.blockIterator < state.windowState.totalNumberOfBlocks ){
				
				if(threadIdx.x == 0)
					blockElements = state.GPU_auxBlocks[state.blockIterator];
				SYNCTHREADS();
				
				if(threadIdx.x < blockElements){
					if( (cond) && (GPU_results[state.blockIterator*blockDim.x+threadIdx.x].rate < newLimit) )
						GPU_results[state.blockIterator*blockDim.x+threadIdx.x] = nullElement;
				}
				
				state.blockIterator += gridDim.x;
				SYNCTHREADS();
			}
		}
	}

//TODO: use CONDITIONS AND FILTERING when implemented

#endif // __CUDACC__
